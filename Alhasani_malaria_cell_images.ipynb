{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Alhasani_malaria_cell_images.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XhVFUo4p9dXu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d8ed2f8d-cc77-4e9f-a407-da50c771db37","executionInfo":{"status":"ok","timestamp":1558586148347,"user_tz":-180,"elapsed":808,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-bWOxl86i248","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","import sys,os\n","import random\n","from sklearn.model_selection import train_test_split\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jm55bS_m-Hte","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":468792,"output_embedded_package_id":"1ZqBmScJ0A3DWr0nP-BO9K8AUzzUMcJAb"},"outputId":"e47ad0fb-ee4c-4c8a-ac14-224f58428643","executionInfo":{"status":"ok","timestamp":1558586196651,"user_tz":-180,"elapsed":23919,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["!wget https://ceb.nlm.nih.gov/proj/malaria/cell_images.zip\n","!unzip cell_images.zip"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"8TcSZblJ-Q9R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"818f1caa-99f4-4dba-e485-decf4547afd1","executionInfo":{"status":"ok","timestamp":1558586316561,"user_tz":-180,"elapsed":2023,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["'{'   cell_images   cell_images.zip   drive   sample_data   train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558586446645,"user_tz":-180,"elapsed":1124,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}},"id":"820nIGaZsqNt","outputId":"95b58b58-d3ad-4637-c22b-b628454e55c0","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","import numpy as np\n","\n","# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558586528582,"user_tz":-180,"elapsed":564,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}},"id":"muHUxcbmm3ID","outputId":"2adf109c-31cf-4386-c0ea-e4e552f5a300","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","# number of subprocesses to use for data loading\n","num_workers = 0\n","# how many samples per batch to load\n","batch_size = 16\n","# percentage of training set to use as validation\n","test_size = 0.2\n","valid_size = 0.2\n","train_size = 0.8\n","\n","# convert data to a normalized torch.FloatTensor\n","transform = transforms.Compose([\n","    transforms.Resize((64,64)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n","    ])\n","\n","dataset = datasets.ImageFolder(\"./cell_images\", transform = transform)\n","dataloader = torch.utils.data.DataLoader(dataset, shuffle = True)\n","\n","# specify the image classes\n","classes = ['Parasitized','Uninfected']\n","\n","# obtain training indices that will be used for validation\n","num_data = len(dataset)\n","indices = list(range(num_data))\n","np.random.seed(3)\n","np.random.shuffle(indices)\n","split = int(np.floor(test_size * num_data))\n","train_idx1, test_idx = indices[split:], indices[:split]\n","\n","num_train_data = len(dataset) - split\n","split2 = int(np.floor(valid_size * num_train_data))\n","train_idx, valid_idx = train_idx1[split2:], train_idx1[:split2]\n","\n","# define samplers for obtaining training and validation batches\n","train_sampler = SubsetRandomSampler(train_idx)\n","test_sampler = SubsetRandomSampler(test_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","# prepare data loaders (combine dataset and sampler)\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n","test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)\n","valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n","print(len(train_idx))\n","print(len(test_idx))\n","print(len(valid_idx))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["17638\n","5511\n","4409\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P0-BU1OU9Yr2","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# helper function to un-normalize and display an image\n","def imshow(img):\n","    img = img / 2 + 0.5  # unnormalize\n","    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2Krn_g69Yr5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":166},"outputId":"3aa4e4b1-e5e5-4b87-b210-a79685a65aed","executionInfo":{"status":"ok","timestamp":1558586536460,"user_tz":-180,"elapsed":798,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["# obtain one batch of training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(25, 4))\n","\n","for idx in np.arange(1):\n","    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n","    print(images[idx].shape)\n","    imshow(images[idx])\n","    ax.set_title(classes[labels[idx]])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(3, 64, 64)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAHgAAACECAYAAABbNO+wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n","text/plain":["<Figure size 1800x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558586542314,"user_tz":-180,"elapsed":745,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}},"id":"X_abZZXgrW9O","outputId":"6bdc4a94-936c-4ab5-a079-9a36bd272853","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","#35\n","# define the CNN architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # convolutional layer (sees 64x64x3 image tensor)\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n","\n","        # convolutional layer (sees 32x32x16 tensor)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        \n","        # max pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.pool1 = nn.MaxPool2d(3, 3)\n","        # linear layer (32 *16*16 -> 512)\n","        self.fc1 = nn.Linear(32 *16*16, 512)\n","        # linear layer (512 -> 256)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 2)\n","    \n","        # dropout layer (p=0.2)\n","        self.dropout = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        # add sequence of convolutional and max pooling layers\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","\n","        # flatten image input\n","        x = x.view(-1,32 *16*16)\n","        # add 1st hidden layer, with relu activation function\n","        x = F.relu(self.fc1(x))\n","        # add dropout layer\n","        x = self.dropout(x)\n","        # add 2nd hidden layer, with relu activation function\n","        x = F.relu(self.fc2(x))\n","        # add dropout layer   \n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        return x\n","# create a complete CNN\n","model = Net()\n","print(model)\n","# move tensors to GPU if CUDA is available\n","if train_on_gpu:\n","    model.cuda()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (pool1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=8192, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc3): Linear(in_features=256, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W6D2ECmUm6s7","colab":{}},"source":["import torch.optim as optim\n","\n","# specify loss function (categorical cross-entropy)\n","criterion = nn.CrossEntropyLoss()\n","\n","# specify optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.01)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1558587260362,"user_tz":-180,"elapsed":710454,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}},"id":"wBHGXGW-m9mQ","outputId":"36360254-2889-4c70-a279-fe67d0704fae","colab":{"base_uri":"https://localhost:8080/","height":850}},"source":["# number of epochs to train the model\n","n_epochs = 100\n","\n","valid_loss_min = np.Inf # track change in validation loss\n","\n","for epoch in range(1, n_epochs+1):\n","\n","    # keep track of training and validation loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    \n","    ###################\n","    # train the model #\n","    ###################\n","    model.train()\n","    for data, target in train_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update training loss\n","        train_loss += loss.item()*data.size(0)\n","        \n","    ######################    \n","    # validate the model #\n","    ######################\n","    model.eval()\n","    for data, target in valid_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # update average validation loss \n","        valid_loss += loss.item()*data.size(0)\n","    \n","    # calculate average losses\n","    train_loss = train_loss/len(train_loader.dataset)\n","    valid_loss = valid_loss/len(valid_loader.dataset)\n","        \n","    # print training/validation statistics \n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","        epoch, train_loss, valid_loss))\n","    \n","    # save model if validation loss has decreased\n","    if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","    \n","        torch.save(model.state_dict(), 'drive/My Drive/ML2/malaria_cnn.pt')\n","        valid_loss_min = valid_loss\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 0.423681 \tValidation Loss: 0.096653\n","Validation loss decreased (inf --> 0.096653).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.369595 \tValidation Loss: 0.080204\n","Validation loss decreased (0.096653 --> 0.080204).  Saving model ...\n","Epoch: 3 \tTraining Loss: 0.220354 \tValidation Loss: 0.034786\n","Validation loss decreased (0.080204 --> 0.034786).  Saving model ...\n","Epoch: 4 \tTraining Loss: 0.136609 \tValidation Loss: 0.037049\n","Epoch: 5 \tTraining Loss: 0.117358 \tValidation Loss: 0.028344\n","Validation loss decreased (0.034786 --> 0.028344).  Saving model ...\n","Epoch: 6 \tTraining Loss: 0.106628 \tValidation Loss: 0.026296\n","Validation loss decreased (0.028344 --> 0.026296).  Saving model ...\n","Epoch: 7 \tTraining Loss: 0.099097 \tValidation Loss: 0.024981\n","Validation loss decreased (0.026296 --> 0.024981).  Saving model ...\n","Epoch: 8 \tTraining Loss: 0.091341 \tValidation Loss: 0.025680\n","Epoch: 9 \tTraining Loss: 0.085347 \tValidation Loss: 0.023630\n","Validation loss decreased (0.024981 --> 0.023630).  Saving model ...\n","Epoch: 10 \tTraining Loss: 0.079880 \tValidation Loss: 0.025345\n","Epoch: 11 \tTraining Loss: 0.075923 \tValidation Loss: 0.023567\n","Validation loss decreased (0.023630 --> 0.023567).  Saving model ...\n","Epoch: 12 \tTraining Loss: 0.070378 \tValidation Loss: 0.022650\n","Validation loss decreased (0.023567 --> 0.022650).  Saving model ...\n","Epoch: 13 \tTraining Loss: 0.066401 \tValidation Loss: 0.021987\n","Validation loss decreased (0.022650 --> 0.021987).  Saving model ...\n","Epoch: 14 \tTraining Loss: 0.062300 \tValidation Loss: 0.023148\n","Epoch: 15 \tTraining Loss: 0.057387 \tValidation Loss: 0.024000\n","Epoch: 16 \tTraining Loss: 0.053416 \tValidation Loss: 0.104793\n","Epoch: 17 \tTraining Loss: 0.049972 \tValidation Loss: 0.025068\n","Epoch: 18 \tTraining Loss: 0.043656 \tValidation Loss: 0.024935\n","Epoch: 19 \tTraining Loss: 0.040522 \tValidation Loss: 0.025452\n","Epoch: 20 \tTraining Loss: 0.034983 \tValidation Loss: 0.025795\n","Epoch: 21 \tTraining Loss: 0.031538 \tValidation Loss: 0.026857\n","Epoch: 22 \tTraining Loss: 0.027195 \tValidation Loss: 0.025007\n","Epoch: 23 \tTraining Loss: 0.022652 \tValidation Loss: 0.028617\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-762591a0e7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m###################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# move tensors to GPU if CUDA is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[1;32m    131\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_image_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_image_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'accimage'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xJNV380i3RaL","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8c16e104-9d84-4c5c-a044-925dffeae2a1","executionInfo":{"status":"ok","timestamp":1558587266468,"user_tz":-180,"elapsed":726,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["#Load the Model with the Lowest Validation Loss\n","model.load_state_dict(torch.load('drive/My Drive/ML2/malaria_cnn.pt'))"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IncompatibleKeys(missing_keys=[], unexpected_keys=[])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558587276757,"user_tz":-180,"elapsed":7945,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}},"id":"3iPqrZ44tjyW","outputId":"784ea13c-9fd2-4315-88cb-ab6d66bbc9a1","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# track test loss\n","test_loss = 0.0\n","class_correct = list(0. for i in range(2))\n","class_total = list(0. for i in range(2))\n","\n","\n","model.eval()\n","# iterate over test data\n","for data, target in test_loader:\n","    # move tensors to GPU if CUDA is available\n","    if train_on_gpu:\n","        data, target = data.cuda(), target.cuda()\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = model(data)\n","    # calculate the batch loss\n","    loss = criterion(output, target)\n","    # update test loss \n","    test_loss += loss.item()*data.size(0)\n","    # convert output probabilities to predicted class\n","    _, pred = torch.max(output, 1)    \n","    # compare predictions to true label\n","    correct_tensor = pred.eq(target.data.view_as(pred))\n","    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","    # calculate test accuracy for each object class\n","   # for i in range(batch_size):\n","    for i in range(len(target)):\n","        label = target.data[i]\n","        if(pred[i] == label):\n","           class_correct[label] += 1\n","        class_total[label] += 1\n","\n","# average test loss\n","test_loss = test_loss/len(test_loader.dataset)\n","print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","for i in range(2):\n","    if class_total[i] > 0:\n","        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","            classes[i], 100 * class_correct[i] / class_total[i],\n","            np.sum(class_correct[i]), np.sum(class_total[i])))\n","    else:\n","        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","    100. * np.sum(class_correct) / np.sum(class_total),\n","    np.sum(class_correct), np.sum(class_total)))\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Test Loss: 0.027612\n","\n","Test Accuracy of Parasitized: 94% (2618/2756)\n","Test Accuracy of Uninfected: 96% (2647/2755)\n","\n","Test Accuracy (Overall): 95% (5265/5511)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MPquOZ5P9YsV","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn, optim\n","from torchvision import transforms, datasets, models\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCDSn5Rr9YsY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":782},"outputId":"e1be3fb1-4c2d-4405-d9e8-937bfd4a0404","executionInfo":{"status":"ok","timestamp":1558587284735,"user_tz":-180,"elapsed":5277,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["#loading the pretrained model \n","model = models.vgg16(pretrained = True)\n","\n","#Freeze the parameters for the model\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","#view all the layer on VGG16 \n","print(model)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace)\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace)\n","    (5): Dropout(p=0.5)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nan2UfeN9Ysc","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F\n","class Classifier(nn.Module):\n","    \n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        \n","        self.hidden1 = nn.Linear(25088,4096)\n","        self.hidden2 = nn.Linear(4096, 4096)\n","        self.output = nn.Linear(4096, 2)\n","        \n","        self.dropout = nn.Dropout(0.5)\n","        \n","    def forward(self, x):\n","        \n","        x = self.dropout(F.relu(self.hidden1(x)))\n","        x = self.dropout(F.relu(self.hidden2(x)))\n","        x = self.output(x)\n","        \n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gq3O1psl9Yse","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"outputId":"e9f4bd52-4d47-428e-b45f-0b2927baa732","executionInfo":{"status":"ok","timestamp":1558587287825,"user_tz":-180,"elapsed":1648,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["#replace the model's default \n","model.classifier = Classifier()\n","\n","print(model)\n","\n","#\n","if train_on_gpu:\n","    model.cuda()\n","\n","#define the lost function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.classifier.parameters(), lr = 0.001, momentum = 0.9)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Classifier(\n","    (hidden1): Linear(in_features=25088, out_features=4096, bias=True)\n","    (hidden2): Linear(in_features=4096, out_features=4096, bias=True)\n","    (output): Linear(in_features=4096, out_features=2, bias=True)\n","    (dropout): Dropout(p=0.5)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YOt4_yau9Ysl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":554},"outputId":"e7595536-bfd2-4681-9b41-eb2c4985f9b1","executionInfo":{"status":"error","timestamp":1558588428175,"user_tz":-180,"elapsed":1137216,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["# number of epochs to train the model\n","n_epochs = 100\n","\n","\n","\n","valid_loss_min = np.Inf # track change in validation loss\n","\n","\n","for epoch in range(1, n_epochs+1):\n","\n","    # keep track of training and validation loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    \n","    ###################\n","    # train the model #\n","    ###################\n","    model.train()\n","    for data, target in train_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update training loss\n","        train_loss += loss.item()*data.size(0)\n","        \n","    ######################    \n","    # validate the model #\n","    ######################\n","    model.eval()\n","    for data, target in valid_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # update average validation loss \n","        valid_loss += loss.item()*data.size(0)\n","    \n","    # calculate average losses\n","    train_loss = train_loss/len(train_loader.dataset)\n","    valid_loss = valid_loss/len(valid_loader.dataset)\n","        \n","    # print training/validation statistics \n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","        epoch, train_loss, valid_loss))\n","    \n","    # save model if validation loss has decreased\n","    if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","       # torch.save(model.state_dict(), 'model_augmented.pt')\n","        torch.save(model.state_dict(),'drive/My Drive/ML2/malaria_transfer_learning.pt')\n","        valid_loss_min = valid_loss\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 0.200640 \tValidation Loss: 0.034406\n","Validation loss decreased (inf --> 0.034406).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.158668 \tValidation Loss: 0.031607\n","Validation loss decreased (0.034406 --> 0.031607).  Saving model ...\n","Epoch: 3 \tTraining Loss: 0.145855 \tValidation Loss: 0.031915\n","Epoch: 4 \tTraining Loss: 0.137070 \tValidation Loss: 0.035310\n","Epoch: 5 \tTraining Loss: 0.133052 \tValidation Loss: 0.030716\n","Validation loss decreased (0.031607 --> 0.030716).  Saving model ...\n","Epoch: 6 \tTraining Loss: 0.129029 \tValidation Loss: 0.028084\n","Validation loss decreased (0.030716 --> 0.028084).  Saving model ...\n","Epoch: 7 \tTraining Loss: 0.127061 \tValidation Loss: 0.028920\n","Epoch: 8 \tTraining Loss: 0.123970 \tValidation Loss: 0.030842\n","Epoch: 9 \tTraining Loss: 0.122137 \tValidation Loss: 0.028415\n","Epoch: 10 \tTraining Loss: 0.119789 \tValidation Loss: 0.029466\n","Epoch: 11 \tTraining Loss: 0.116889 \tValidation Loss: 0.032881\n","Epoch: 12 \tTraining Loss: 0.116164 \tValidation Loss: 0.030122\n","Epoch: 13 \tTraining Loss: 0.112421 \tValidation Loss: 0.028786\n","Epoch: 14 \tTraining Loss: 0.109290 \tValidation Loss: 0.033024\n","Epoch: 15 \tTraining Loss: 0.108125 \tValidation Loss: 0.031486\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-b9c0d2ab4f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# update average validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# calculate average losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"bT9INHxB9Ysq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"de05d5c4-2f17-447d-e7d6-b5f4db865e18","executionInfo":{"status":"ok","timestamp":1558588433181,"user_tz":-180,"elapsed":1455,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["#Load the Model with the Lowest Validation Loss\n","\n","model.load_state_dict(torch.load('drive/My Drive/ML2/malaria_transfer_learning.pt'))"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IncompatibleKeys(missing_keys=[], unexpected_keys=[])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"Vg_zQoPu9Yss","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"24449102-070b-466d-eb6d-80f253229438","executionInfo":{"status":"ok","timestamp":1558588445139,"user_tz":-180,"elapsed":12473,"user":{"displayName":"batoul alhassany","photoUrl":"","userId":"07438840849110152279"}}},"source":["\n","# track test loss\n","test_loss = 0.0\n","class_correct = list(0. for i in range(2))\n","class_total = list(0. for i in range(2))\n","\n","model.eval()\n","# iterate over test data\n","for data, target in test_loader:\n","    # move tensors to GPU if CUDA is available\n","    if train_on_gpu:\n","        data, target = data.cuda(), target.cuda()\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = model(data)\n","    # calculate the batch loss\n","    loss = criterion(output, target)\n","    # update test loss \n","    test_loss += loss.item()*data.size(0)\n","    # convert output probabilities to predicted class\n","    _, pred = torch.max(output, 1)    \n","    # compare predictions to true label\n","    correct_tensor = pred.eq(target.data.view_as(pred))\n","    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","    # calculate test accuracy for each object class\n","   # for i in range(batch_size):\n","    for i in range(len(target)):\n","        label = target.data[i]\n","        if(pred[i] == label):\n","           class_correct[label] += 1\n","        class_total[label] += 1\n","\n","# average test loss\n","test_loss = test_loss/len(test_loader.dataset)\n","print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","for i in range(2):\n","    if class_total[i] > 0:\n","        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","            classes[i], 100 * class_correct[i] / class_total[i],\n","            np.sum(class_correct[i]), np.sum(class_total[i])))\n","    else:\n","        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","    100. * np.sum(class_correct) / np.sum(class_total),\n","    np.sum(class_correct), np.sum(class_total)))\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Test Loss: 0.035237\n","\n","Test Accuracy of Parasitized: 92% (2558/2756)\n","Test Accuracy of Uninfected: 94% (2601/2755)\n","\n","Test Accuracy (Overall): 93% (5159/5511)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d5S2cm6c9Ys1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}